# ============================================
# Knowledge Base Service Configuration
# ============================================
# Copy this file to .env and customize as needed

# Server
PORT=8080
HOST=0.0.0.0

# ============================================
# LLM Provider Configuration (统一配置)
# ============================================
# Provider 类型: deepseek | openai | anthropic | litellm | custom
# 必须配置有效的 LLM_API_KEY
LLM_PROVIDER=deepseek

# 模型名称
LLM_MODEL=deepseek-chat

# API Key
LLM_API_KEY=sk-xxx

# Base URL (可选，各 provider 有默认值)
# deepseek: https://api.deepseek.com/v1
# openai: https://api.openai.com/v1
# anthropic: https://api.anthropic.com/v1
# litellm: http://localhost:4000/v1
LLM_BASE_URL=

# Provider 超时配置
LLM_TIMEOUT_MS=60000
LLM_MAX_RETRIES=2
LLM_RETRY_DELAY_MS=1000

# ============================================
# txtai Configuration
# ============================================
TXTAI_URL=http://localhost:8000
TXTAI_API_KEY=
TXTAI_TIMEOUT=30000

# ============================================
# Search Configuration
# ============================================
DEFAULT_SEARCH_LIMIT=5
MAX_SEARCH_LIMIT=20
MIN_SEARCH_SCORE=0.3

# txtai hybrid search weights: [vector_weight, bm25_weight]
# Format: "0.4,0.6" means 40% vector search, 60% keyword search
# For precise terms (like "报价"), increase BM25 weight (e.g., "0.3,0.7")
# For semantic queries, increase vector weight (e.g., "0.7,0.3")
# Default: "0.4,0.6" (slightly favor keyword search for better precision)
TXTAI_HYBRID_WEIGHTS=0.4,0.6

# ============================================
# Query Processing (使用内置 LLM)
# ============================================
# 是否启用 LLM 查询处理（默认: true）
QUERY_LLM_ENABLED=true

# 查询扩展：生成多个查询变体提高召回率
QUERY_EXPANSION_ENABLED=true
QUERY_EXPANSION_MAX=3

# ============================================
# Chat Configuration
# ============================================
CHAT_DEFAULT_TEMPERATURE=0.7
CHAT_DEFAULT_MAX_TOKENS=2048
CHAT_DEFAULT_SEARCH_LIMIT=5

# 系统提示词模板 ({context} 会被替换为知识库上下文)
CHAT_SYSTEM_PROMPT=你是一个专业的知识库助手。请根据以下知识库内容回答用户问题：\n\n{context}\n\n要求：\n1. 回答要准确、专业\n2. 如果知识库内容不足以回答问题，请诚实告知\n3. 适当引用来源内容

# ============================================
# Rate Limiting Configuration
# ============================================
# LLM 请求限流
LLM_RATE_LIMIT_MAX_TOKENS=10
LLM_RATE_LIMIT_REFILL_RATE=2

# LLM 请求队列
LLM_QUEUE_CONCURRENCY=5
LLM_QUEUE_MAX_SIZE=50

# Chat 请求限流
CHAT_RATE_LIMIT_MAX_TOKENS=20
CHAT_RATE_LIMIT_REFILL_RATE=5

# ============================================
# Storage (SQLite 持久化)
# ============================================
# 数据存储路径（包含 SQLite 数据库 knowledgebase.db）
STORAGE_PATH=./data/documents
MEDIA_PATH=./data/media
MEDIA_BASE_URL=http://localhost:8080/media
MAX_FILE_SIZE=10485760

# ============================================
# Chunking
# ============================================
CHUNK_SIZE=500
CHUNK_OVERLAP=50

# Provider identification
PROVIDER_NAME=customer_kb

# Debug mode
DEBUG=false
