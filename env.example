# Knowledge Base Provider Configuration
# Copy this file to .env and customize as needed

# Server
PORT=8080
HOST=0.0.0.0

# txtai configuration
TXTAI_URL=http://localhost:8000
TXTAI_API_KEY=
TXTAI_TIMEOUT=30000

# Storage
STORAGE_PATH=./data/documents
MEDIA_PATH=./data/media
MEDIA_BASE_URL=http://localhost:8080/media
MAX_FILE_SIZE=10485760

# Search configuration
DEFAULT_SEARCH_LIMIT=5
MAX_SEARCH_LIMIT=20
MIN_SEARCH_SCORE=0.3
# txtai hybrid search weights: [vector_weight, bm25_weight]
# Format: "0.4,0.6" means 40% vector search, 60% keyword search
# For precise terms (like "报价"), increase BM25 weight (e.g., "0.3,0.7")
# For semantic queries, increase vector weight (e.g., "0.7,0.3")
# Default: "0.4,0.6" (slightly favor keyword search for better precision)
TXTAI_HYBRID_WEIGHTS=0.4,0.6

# Chunking configuration
CHUNK_SIZE=500
CHUNK_OVERLAP=50

# Provider identification
PROVIDER_NAME=customer_kb

# Query Processing Configuration
# Enable LLM-based query rewriting (default: false, uses rule-based fallback)
QUERY_LLM_ENABLED=false
# LLM service URL (default: llm-adapter at port 26404)
QUERY_LLM_URL=http://localhost:26404
# LLM request timeout in milliseconds (default: 10000ms)
QUERY_LLM_TIMEOUT=10000
# Query expansion: Generate multiple query variants for better recall (default: true if LLM enabled)
QUERY_EXPANSION_ENABLED=true
# Maximum number of expanded queries to generate (default: 3)
QUERY_EXPANSION_MAX=3

# Debug mode
DEBUG=false

